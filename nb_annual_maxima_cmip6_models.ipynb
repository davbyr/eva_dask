{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5220ca-dcae-4d81-816d-c24dbe8cce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import sys\n",
    "import eva_dask\n",
    "from eva_import return_values, model_fitting, extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bb109-5864-4309-ab35-57ba04115775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Inputs\n",
    "fn_input = glob.glob(\"<Paths to input files>\")\n",
    "\n",
    "# Estimating of annual maxima\n",
    "dn_maxima = '<Directory to save extremes from individual models>'\n",
    "fn_maxima = '<Full path to output extremes file>'\n",
    "concat_dimension= 'year' # Name of dimension to concatenate\n",
    "models_to_omit = ['UKESM1-0-LL', 'EC-Earth3','EC-Earth3-Veg']\n",
    "\n",
    "# Fitting of GEV\n",
    "fn_gev = '<Path to output model parameters file'\n",
    "chunks_for_gev = [-1, 25, 25]\n",
    "\n",
    "# Return Values\n",
    "fn_rv = '<Path to output return values file>'\n",
    "input_rl = [20, 25, 30, 32,35]\n",
    "input_rp = [1,2,5,10,50,100,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4751e7e-1bbf-4b40-8889-be785d5f8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect Dask client\n",
    "client = Client(\"tcp://127.0.0.1:<Dask Cluster Port>\")\n",
    "client.upload_file('<Path to eva_dask.py>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f479f7-0dd1-4d98-a99d-1e420045e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxima_files = glob.glob(os.path.join(dn_maxima, '*'))\n",
    "for ff in maxima_files:\n",
    "    os.remove(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c211b1c-f4f0-4b08-b778-135fab4d425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(fn_maxima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885fd73-4d38-421f-b549-38131f6517b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(fn_gev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5dcaf-e2f6-4557-b798-415776af4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(fn_rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee386b-a272-4b08-8e94-76facf58e7f5",
   "metadata": {},
   "source": [
    "### 1. CALCULATE ANNUAL MAXIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a87f4-72b8-4fbd-84a7-1683d2f145c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_files = len(fn_input)\n",
    "dataset_list = [ xr.open_zarr(fn) for fn in fn_input ]\n",
    "\n",
    "for dd in range(n_files):\n",
    "    \n",
    "    dataset = dataset_list[dd]\n",
    "    \n",
    "    start_year = int(fn_input[dd][-9:-5])\n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date   = start_date + timedelta(days = dataset.dims['time'] - 1)\n",
    "    time = pd.date_range(start_date, end_date, freq='1D')\n",
    "    \n",
    "    dataset['time'] = time\n",
    "    \n",
    "    annual_maxima = extremes.annual_maxima(dataset)\n",
    "    \n",
    "    filebase = os.path.basename(fn_input[dd])\n",
    "    annual_maxima.to_netcdf( os.path.join(dn_maxima, filebase+'.nc') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8b31c-e018-417c-b966-2db9123d084a",
   "metadata": {},
   "source": [
    "### 2. CONCATENATE ANNUAL MAXIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547d59b-90cc-4571-a34a-65c611f4c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filenames of maxima datasets to concatenate\n",
    "files_to_concat = glob.glob(os.path.join(dn_maxima, '*'))\n",
    "\n",
    "# Open all of the datasets lazily into a list\n",
    "datasets = [ xr.open_dataset(fn, chunks={}) for fn in files_to_concat ]\n",
    "\n",
    "# Generate the names of each model to preserve information in concatenated dataset\n",
    "omit_idx = []\n",
    "for dd in np.arange( len( datasets ) ):\n",
    "    model_name = os.path.basename(files_to_concat[dd])[:-26]\n",
    "    if model_name in models_to_omit:\n",
    "        omit_idx.append(dd)\n",
    "    string_list = [model_name for ii in range(datasets[dd].dims[concat_dimension])]\n",
    "    datasets[dd]['model_name'] = (['year'], string_list)\n",
    "    \n",
    "# Remove any omitted models\n",
    "if len(omit_idx) > 0:\n",
    "    for ii in omit_idx[::-1]:\n",
    "        print('Removed model by name {0}'.format(datasets[ii].model_name[0].values))\n",
    "        del datasets[ii]\n",
    "    \n",
    "# Concatenate using xarray and rechunk to have all of concat dimension in one chunk (probably time)\n",
    "datasets_concat = xr.concat(datasets, dim=concat_dimension)\n",
    "datasets_concat = datasets_concat.chunk({concat_dimension:-1})\n",
    "\n",
    "# Write to file\n",
    "datasets_concat.to_netcdf( fn_maxima )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b8dcf-6394-453c-b59c-7f179aa2caae",
   "metadata": {},
   "source": [
    "### 3. FIT GEV TO EXTREMES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607e58b-1baf-4349-8157-b6d18a428d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(fn_maxima, chunks={'lat':25, 'lon':25})\n",
    "data = dataset.Twb.load().data\n",
    "data = da.from_array(data, chunks=chunks_for_gev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be408df-96a5-4b9c-9b7c-39883ebf71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mapped = model_fitting.fit_gev_model(data, 'genextreme', 5, 100)\n",
    "mapped = mapped.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04689a8-3142-4403-bb86-3d8b0b7549e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write GEV fit to file\n",
    "ds = xr.Dataset(coords = dict( \n",
    "                    lat = (['lat'], dataset.lat.values),\n",
    "                    lon = (['lon'], dataset.lon.values),\n",
    "                    param = (['param'], ['shape','loc','scale']) ),\n",
    "                data_vars=dict( \n",
    "                    parameters = (['param','lat','lon'], mapped[:3]),\n",
    "                    ks_pvalue = (['lat','lon'], mapped[3])))\n",
    "ds.to_netcdf(fn_gev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe877eb-412c-424c-86fb-6a6beb45e0fa",
   "metadata": {},
   "source": [
    "### 4. Calculate Return Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5ede1-96f1-488b-8e3a-d135c425a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_params = xr.open_dataset(fn_gev)\n",
    "params = da.from_array( ds_params['parameters'].data )\n",
    "params = params.rechunk([-1, 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad59d5-90d4-477d-a5df-81afc87365e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rl = return_values.return_levels_from_fit(params, stats.genextreme,\n",
    "                                          input_rp).compute()\n",
    "rp = return_values.return_periods_from_fit(params, stats.genextreme,\n",
    "                                           input_rl).compute()\n",
    "\n",
    "# Extract pvalues array to put into output array\n",
    "pvalues = ds_params.ks_pvalue.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7546957-e6ad-44c2-bbba-83528e04a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to xarray Dataset\n",
    "ds = xr.Dataset(coords = dict( \n",
    "                    lat = (['lat'], ds_params.lat.values),\n",
    "                    lon = (['lon'], ds_params.lon.values),\n",
    "                    return_level = (['return_level'], input_rl),\n",
    "                    return_period = (['return_period'], input_rp)),\n",
    "                data_vars=dict( calculated_rl = (['return_period', 'lat', 'lon'], rl),\n",
    "                    calculated_rp = (['return_level', 'lat', 'lon'], rp),\n",
    "                    pvalues       = (['lat', 'lon'], pvalues)))\n",
    "ds.to_netcdf(fn_rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d47348-b82c-48e5-abdb-3ce1e75a73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
